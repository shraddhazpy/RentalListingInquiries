{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>building_id</th>\n",
       "      <th>created</th>\n",
       "      <th>description</th>\n",
       "      <th>display_address</th>\n",
       "      <th>features</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>photos</th>\n",
       "      <th>price</th>\n",
       "      <th>street_address</th>\n",
       "      <th>interest_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>53a5b119ba8f7b61d4e010512e0dfc85</td>\n",
       "      <td>2016-06-24 07:54:24</td>\n",
       "      <td>A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...</td>\n",
       "      <td>Metropolitan Avenue</td>\n",
       "      <td>[]</td>\n",
       "      <td>40.7145</td>\n",
       "      <td>7211212</td>\n",
       "      <td>-73.9425</td>\n",
       "      <td>5ba989232d0489da1b5f2c45f6688adc</td>\n",
       "      <td>[https://photos.renthop.com/2/7211212_1ed4542e...</td>\n",
       "      <td>3000</td>\n",
       "      <td>792 Metropolitan Avenue</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>c5c8a357cba207596b04d1afd1e4f130</td>\n",
       "      <td>2016-06-12 12:19:27</td>\n",
       "      <td></td>\n",
       "      <td>Columbus Avenue</td>\n",
       "      <td>[Doorman, Elevator, Fitness Center, Cats Allow...</td>\n",
       "      <td>40.7947</td>\n",
       "      <td>7150865</td>\n",
       "      <td>-73.9667</td>\n",
       "      <td>7533621a882f71e25173b27e3139d83d</td>\n",
       "      <td>[https://photos.renthop.com/2/7150865_be3306c5...</td>\n",
       "      <td>5465</td>\n",
       "      <td>808 Columbus Avenue</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>c3ba40552e2120b0acfc3cb5730bb2aa</td>\n",
       "      <td>2016-04-17 03:26:41</td>\n",
       "      <td>Top Top West Village location, beautiful Pre-w...</td>\n",
       "      <td>W 13 Street</td>\n",
       "      <td>[Laundry In Building, Dishwasher, Hardwood Flo...</td>\n",
       "      <td>40.7388</td>\n",
       "      <td>6887163</td>\n",
       "      <td>-74.0018</td>\n",
       "      <td>d9039c43983f6e564b1482b273bd7b01</td>\n",
       "      <td>[https://photos.renthop.com/2/6887163_de85c427...</td>\n",
       "      <td>2850</td>\n",
       "      <td>241 W 13 Street</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28d9ad350afeaab8027513a3e52ac8d5</td>\n",
       "      <td>2016-04-18 02:22:02</td>\n",
       "      <td>Building Amenities - Garage - Garden - fitness...</td>\n",
       "      <td>East 49th Street</td>\n",
       "      <td>[Hardwood Floors, No Fee]</td>\n",
       "      <td>40.7539</td>\n",
       "      <td>6888711</td>\n",
       "      <td>-73.9677</td>\n",
       "      <td>1067e078446a7897d2da493d2f741316</td>\n",
       "      <td>[https://photos.renthop.com/2/6888711_6e660cee...</td>\n",
       "      <td>3275</td>\n",
       "      <td>333 East 49th Street</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100013</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-28 01:32:41</td>\n",
       "      <td>Beautifully renovated 3 bedroom flex 4 bedroom...</td>\n",
       "      <td>West 143rd Street</td>\n",
       "      <td>[Pre-War]</td>\n",
       "      <td>40.8241</td>\n",
       "      <td>6934781</td>\n",
       "      <td>-73.9493</td>\n",
       "      <td>98e13ad4b495b9613cef886d79a6291f</td>\n",
       "      <td>[https://photos.renthop.com/2/6934781_1fa4b41a...</td>\n",
       "      <td>3350</td>\n",
       "      <td>500 West 143rd Street</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bathrooms  bedrooms                       building_id  \\\n",
       "10            1.5         3  53a5b119ba8f7b61d4e010512e0dfc85   \n",
       "10000         1.0         2  c5c8a357cba207596b04d1afd1e4f130   \n",
       "100004        1.0         1  c3ba40552e2120b0acfc3cb5730bb2aa   \n",
       "100007        1.0         1  28d9ad350afeaab8027513a3e52ac8d5   \n",
       "100013        1.0         4                                 0   \n",
       "\n",
       "                    created  \\\n",
       "10      2016-06-24 07:54:24   \n",
       "10000   2016-06-12 12:19:27   \n",
       "100004  2016-04-17 03:26:41   \n",
       "100007  2016-04-18 02:22:02   \n",
       "100013  2016-04-28 01:32:41   \n",
       "\n",
       "                                              description  \\\n",
       "10      A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...   \n",
       "10000                                                       \n",
       "100004  Top Top West Village location, beautiful Pre-w...   \n",
       "100007  Building Amenities - Garage - Garden - fitness...   \n",
       "100013  Beautifully renovated 3 bedroom flex 4 bedroom...   \n",
       "\n",
       "            display_address  \\\n",
       "10      Metropolitan Avenue   \n",
       "10000       Columbus Avenue   \n",
       "100004          W 13 Street   \n",
       "100007     East 49th Street   \n",
       "100013    West 143rd Street   \n",
       "\n",
       "                                                 features  latitude  \\\n",
       "10                                                     []   40.7145   \n",
       "10000   [Doorman, Elevator, Fitness Center, Cats Allow...   40.7947   \n",
       "100004  [Laundry In Building, Dishwasher, Hardwood Flo...   40.7388   \n",
       "100007                          [Hardwood Floors, No Fee]   40.7539   \n",
       "100013                                          [Pre-War]   40.8241   \n",
       "\n",
       "        listing_id  longitude                        manager_id  \\\n",
       "10         7211212   -73.9425  5ba989232d0489da1b5f2c45f6688adc   \n",
       "10000      7150865   -73.9667  7533621a882f71e25173b27e3139d83d   \n",
       "100004     6887163   -74.0018  d9039c43983f6e564b1482b273bd7b01   \n",
       "100007     6888711   -73.9677  1067e078446a7897d2da493d2f741316   \n",
       "100013     6934781   -73.9493  98e13ad4b495b9613cef886d79a6291f   \n",
       "\n",
       "                                                   photos  price  \\\n",
       "10      [https://photos.renthop.com/2/7211212_1ed4542e...   3000   \n",
       "10000   [https://photos.renthop.com/2/7150865_be3306c5...   5465   \n",
       "100004  [https://photos.renthop.com/2/6887163_de85c427...   2850   \n",
       "100007  [https://photos.renthop.com/2/6888711_6e660cee...   3275   \n",
       "100013  [https://photos.renthop.com/2/6934781_1fa4b41a...   3350   \n",
       "\n",
       "                 street_address interest_level  \n",
       "10      792 Metropolitan Avenue         medium  \n",
       "10000       808 Columbus Avenue            low  \n",
       "100004          241 W 13 Street           high  \n",
       "100007     333 East 49th Street            low  \n",
       "100013    500 West 143rd Street            low  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset= pd.read_json('train.json')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low       34284\n",
       "medium    11229\n",
       "high       3839\n",
       "Name: interest_level, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['interest_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low       0.694683\n",
       "medium    0.227529\n",
       "high      0.077788\n",
       "Name: interest_level, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Checking the percentages of points belonging to the three classes present in the dataset\n",
    "dataset['interest_level'].value_counts()/ len(dataset['interest_level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Splitting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test= train_test_split(dataset, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low       24035\n",
       "medium     7879\n",
       "high       2632\n",
       "Name: interest_level, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Checking the no of points belonging to each of the classes in the train dataset\n",
    "train['interest_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low       0.695739\n",
       "medium    0.228073\n",
       "high      0.076188\n",
       "Name: interest_level, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Checking the percentage of points given to each of the classes for the train dataset\n",
    "train['interest_level'].value_counts()/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low       10249\n",
       "medium     3350\n",
       "high       1207\n",
       "Name: interest_level, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Checking the no of points belonging to each of the classes in the test dataset\n",
    "test['interest_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low       0.692219\n",
       "medium    0.226260\n",
       "high      0.081521\n",
       "Name: interest_level, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Checking the percentage of points given to each of the classes in the test dataset\n",
    "test['interest_level'].value_counts()/len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineered features for created date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Utility function\n",
    "def get_days_months_year(dt):\n",
    "    try:\n",
    "        return pd.Series([datetime.strptime(dt, '%Y-%m-%d %H:%M:%S').day,datetime.strptime(dt, '%Y-%m-%d %H:%M:%S').month,\\\n",
    "                          datetime.strptime(dt, '%Y-%m-%d %H:%M:%S').year])\n",
    "    except ValueError:\n",
    "        return pd.Series([0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting month, day and year from the date feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Day, Month and year feature for the train dataset\n",
    "train[['day', 'month', 'year']] = train['created'].apply(get_days_months_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Day, Month and year feature for the test dataset\n",
    "test[['day', 'month', 'year']] = test['created'].apply(get_days_months_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function for response coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_response_dict(dataframe, feature, class_):\n",
    "    data= dataframe[[feature, class_]]\n",
    "    dict_= {}\n",
    "    for i in data[feature].unique():\n",
    "        vals= []\n",
    "        for j in data[class_].unique():\n",
    "            vals.append((len(data[(data[feature] == i) & (data[class_] ==j )]))/ len(data[data[feature] == i]))\n",
    "        dict_[i] = [k * len(data[data[feature] == i]) for k in vals]\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_response_coding(feature, dict_):\n",
    "    if feature in dict_.keys():\n",
    "        return pd.Series(dict_[feature])\n",
    "    else:\n",
    "        return pd.Series([1/3, 1/3,1/3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing response coding for building id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 0:03:26.345983\n"
     ]
    }
   ],
   "source": [
    "start= datetime.now()\n",
    "dict_building_id= create_response_dict(dataframe=train, feature= 'building_id', class_='interest_level')\n",
    "print('Time taken {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Response coding for the train dataset\n",
    "train[['building_id_0','building_id_1','building_id_2']] = train['building_id'].apply(transform_response_coding, dict_= dict_building_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Response coding for the test dataset\n",
    "test[['building_id_0','building_id_1','building_id_2']] = test['building_id'].apply(transform_response_coding, dict_= dict_building_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing response coding for manager id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 0:01:43.400994\n"
     ]
    }
   ],
   "source": [
    "start= datetime.now()\n",
    "dict_manager_id= create_response_dict(dataframe=train, feature= 'manager_id', class_='interest_level')\n",
    "print('Time taken {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['manager_id_0','manager_id_1','manager_id_2']] = train['manager_id'].apply(transform_response_coding, dict_= dict_manager_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['manager_id_0','manager_id_1','manager_id_2']] = test['manager_id'].apply(transform_response_coding, dict_= dict_manager_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function for text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_eng= stopwords.words('english')\n",
    "stemmr= SnowballStemmer('english')\n",
    "def clean_data(text, stop_and_stem=True, just_alpha= False, is_list= False,):\n",
    "    ## joining a list\n",
    "    if is_list:\n",
    "        text= ' '.join(text)\n",
    "    \n",
    "    ## Removing the html tags\n",
    "    soup = BeautifulSoup(text)\n",
    "    text= soup.get_text()\n",
    "    \n",
    "    ##Removing the special characters\n",
    "    if just_alpha:\n",
    "        text = re.sub('[^a-zA-Z ]',' ', text )\n",
    "    else:\n",
    "        text = re.sub('[^a-zA-Z0-9 ]',' ', text )\n",
    "    \n",
    "    ##Lowercasing, stemming and removing the stopwords\n",
    "    text= word_tokenize(text)\n",
    "    \n",
    "    \n",
    "    if stop_and_stem == True:\n",
    "        text= ' '.join([stemmr.stem(i.lower()) for i in text if i not in stop_eng])\n",
    "    \n",
    "    else:\n",
    "        text= ' '.join(list(map(lambda x:x.lower(),text)))\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding for features variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_feat= CountVectorizer(min_df=3)\n",
    "##Train\n",
    "count_vect_features_train= count_vect_feat.fit_transform(train['features'].\\\n",
    "                                                   apply(clean_data, stop_and_stem= False, just_alpha=True, is_list=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test\n",
    "count_vect_features_test = count_vect_feat.transform(test['features'].\\\n",
    "                                                   apply(clean_data, stop_and_stem= False, just_alpha=True, is_list=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vect_feat.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a new featue as - Length of the feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train\n",
    "train['len_features']= train['features'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test\n",
    "test['len_features']= test['features'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding the Display address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16285                         w 151 street\n",
       "8514                          worth street\n",
       "43025                     south 4th street\n",
       "33847    east 29th street lexington avenue\n",
       "64052                       central park w\n",
       "64394                            w 70th st\n",
       "31868                     east 75th street\n",
       "97560                            gates ave\n",
       "92520               avenue of the americas\n",
       "96530                              2nd ave\n",
       "Name: display_address, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['display_address'][:10].apply(clean_data, stop_and_stem= False, just_alpha=False, is_list=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_displ= CountVectorizer(min_df=5)\n",
    "##Train\n",
    "count_vect_display_address_train= count_vect_displ.fit_transform(train['display_address'].apply\\\n",
    "                                                   (clean_data, stop_and_stem= False, just_alpha=False, is_list=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test\n",
    "count_vect_display_address_test= count_vect_displ.transform(test['display_address'].apply\\\n",
    "                                                   (clean_data, stop_and_stem= False, just_alpha=False, is_list=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vect_displ.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding the Street address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16285              609 w 151 street\n",
       "8514               111 worth street\n",
       "43025          120 south 4th street\n",
       "33847          145 east 29th street\n",
       "64052            241 central park w\n",
       "64394                 200 w 70th st\n",
       "31868          300 east 75th street\n",
       "97560                1670 gates ave\n",
       "92520    777 avenue of the americas\n",
       "96530                   530 2nd ave\n",
       "Name: street_address, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['street_address'][:10].apply(clean_data, stop_and_stem= False, just_alpha=False, is_list=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_strt= CountVectorizer(min_df=5)\n",
    "count_vect_strt_address_train= count_vect_strt.fit_transform(train['street_address'].apply\\\n",
    "                                                   (clean_data, stop_and_stem= False, just_alpha=False, is_list=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_strt_address_test= count_vect_strt.transform(test['street_address'].apply\\\n",
    "                                                   (clean_data, stop_and_stem= False, just_alpha=False, is_list=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1239"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vect_strt.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the description feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cleaned_description']= train['description'].apply(clean_data, stop_and_stem= True, just_alpha=False, is_list=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['cleaned_description']= test['description'].apply(clean_data, stop_and_stem= True, just_alpha=False, is_list=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words vectorization of the description feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_desc= CountVectorizer(min_df=5)\n",
    "count_vect_description_train= count_vect_desc.fit_transform(train['cleaned_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_description_test= count_vect_desc.transform(test['cleaned_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34546, 8771)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect_description_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf vectorization of the description feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_desc= TfidfVectorizer(min_df=5)\n",
    "tfidf_description_train= tfidf_desc.fit_transform(train['cleaned_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_description_test= tfidf_desc.transform(test['cleaned_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34546, 8771)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_description_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg W2V vectorization of the description feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Creating a list of sentences\n",
    "i=0\n",
    "list_of_sent=[]\n",
    "for sent in train['cleaned_description'].values:\n",
    "    list_of_sent.append(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(list_of_sent, size=60,workers=8)\n",
    "w2v_words= list(w2v_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34546/34546 [00:35<00:00, 974.21it/s] \n"
     ]
    }
   ],
   "source": [
    "sent_to_vect=[]\n",
    "for sublist in tqdm(list_of_sent):\n",
    "    vector= np.zeros(60)\n",
    "    cnt= 0\n",
    "    for word in sublist:\n",
    "        if word in w2v_words:\n",
    "            vector += w2v_model.wv[word]\n",
    "            cnt += 1\n",
    "    if cnt >0:\n",
    "        sent_to_vect.append(vector/cnt) \n",
    "    else:\n",
    "        sent_to_vect.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_to_vec_avgw2v_train= np.asarray(sent_to_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Creating a list of sentences for the test data\n",
    "i=0\n",
    "list_of_sent_test=[]\n",
    "for sent in test['cleaned_description'].values:\n",
    "    list_of_sent_test.append(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14806/14806 [00:15<00:00, 981.98it/s] \n"
     ]
    }
   ],
   "source": [
    "sent_to_vect_test=[]\n",
    "for sublist in tqdm(list_of_sent_test):\n",
    "    vector= np.zeros(60)\n",
    "    cnt= 0\n",
    "    for word in sublist:\n",
    "        if word in w2v_words:\n",
    "            vector += w2v_model.wv[word]\n",
    "            cnt += 1\n",
    "    if cnt >0:\n",
    "        sent_to_vect_test.append(vector/cnt)\n",
    "    else:\n",
    "        sent_to_vect_test.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_to_vec_avgw2v_test= np.asarray(sent_to_vect_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf W2V vectorization of the description feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf= TfidfVectorizer(tokenizer=lambda x:x.split())\n",
    "tfidf_vect= tfidf.fit_transform(train['cleaned_description'])\n",
    "dictionary = dict(zip(tfidf.get_feature_names(), list(tfidf.idf_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34546/34546 [00:50<00:00, 684.16it/s]\n"
     ]
    }
   ],
   "source": [
    "sent_to_vect=[]\n",
    "for sublist in tqdm(list_of_sent):\n",
    "    vector= np.zeros(60)\n",
    "    tf_idf= 0\n",
    "    for word in sublist:\n",
    "        if word in w2v_words:\n",
    "            tf_idf_word= sublist.count(word) * dictionary[word]\n",
    "            vector += (w2v_model.wv[word] * tf_idf_word)\n",
    "            tf_idf += tf_idf_word\n",
    "    if tf_idf >0:\n",
    "        sent_to_vect.append(vector/tf_idf)\n",
    "    else:\n",
    "        sent_to_vect.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_to_vec_tfidfw2v= np.asarray(sent_to_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14806/14806 [00:21<00:00, 676.38it/s]\n"
     ]
    }
   ],
   "source": [
    "sent_to_vect_test=[]\n",
    "for sublist in tqdm(list_of_sent_test):\n",
    "    vector= np.zeros(60)\n",
    "    tf_idf= 0\n",
    "    for word in sublist:\n",
    "        if word in w2v_words:\n",
    "            tf_idf_word= sublist.count(word) * dictionary[word]\n",
    "            vector += (w2v_model.wv[word] * tf_idf_word)\n",
    "            tf_idf += tf_idf_word\n",
    "    if tf_idf >0:\n",
    "        sent_to_vect_test.append(vector/tf_idf)\n",
    "    else:\n",
    "        sent_to_vect_test.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_to_vec_tfidfw2v_test= np.asarray(sent_to_vect_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Spacy's Word2Vec to featurize the description feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34546/34546 [05:32<00:00, 103.74it/s]\n"
     ]
    }
   ],
   "source": [
    "spacy_vectors=[]\n",
    "for document in tqdm(train['cleaned_description'][:]):\n",
    "    token= nlp(document)\n",
    "    spacy_vectors.append(token.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_to_vec_spacy = np.asarray(spacy_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14806/14806 [02:25<00:00, 101.92it/s]\n"
     ]
    }
   ],
   "source": [
    "spacy_vectors=[]\n",
    "for document in tqdm(test['cleaned_description']):\n",
    "    token= nlp(document)\n",
    "    spacy_vectors.append(token.vector.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_to_vec_spacy_test = np.asarray(spacy_vectors) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Preparation of the datasets for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>building_id</th>\n",
       "      <th>created</th>\n",
       "      <th>description</th>\n",
       "      <th>display_address</th>\n",
       "      <th>features</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>photos</th>\n",
       "      <th>price</th>\n",
       "      <th>street_address</th>\n",
       "      <th>interest_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>53a5b119ba8f7b61d4e010512e0dfc85</td>\n",
       "      <td>2016-06-24 07:54:24</td>\n",
       "      <td>A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...</td>\n",
       "      <td>Metropolitan Avenue</td>\n",
       "      <td>[]</td>\n",
       "      <td>40.7145</td>\n",
       "      <td>7211212</td>\n",
       "      <td>-73.9425</td>\n",
       "      <td>5ba989232d0489da1b5f2c45f6688adc</td>\n",
       "      <td>[https://photos.renthop.com/2/7211212_1ed4542e...</td>\n",
       "      <td>3000</td>\n",
       "      <td>792 Metropolitan Avenue</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>c5c8a357cba207596b04d1afd1e4f130</td>\n",
       "      <td>2016-06-12 12:19:27</td>\n",
       "      <td></td>\n",
       "      <td>Columbus Avenue</td>\n",
       "      <td>[Doorman, Elevator, Fitness Center, Cats Allow...</td>\n",
       "      <td>40.7947</td>\n",
       "      <td>7150865</td>\n",
       "      <td>-73.9667</td>\n",
       "      <td>7533621a882f71e25173b27e3139d83d</td>\n",
       "      <td>[https://photos.renthop.com/2/7150865_be3306c5...</td>\n",
       "      <td>5465</td>\n",
       "      <td>808 Columbus Avenue</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bathrooms  bedrooms                       building_id  \\\n",
       "10           1.5         3  53a5b119ba8f7b61d4e010512e0dfc85   \n",
       "10000        1.0         2  c5c8a357cba207596b04d1afd1e4f130   \n",
       "\n",
       "                   created                                        description  \\\n",
       "10     2016-06-24 07:54:24  A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...   \n",
       "10000  2016-06-12 12:19:27                                                      \n",
       "\n",
       "           display_address                                           features  \\\n",
       "10     Metropolitan Avenue                                                 []   \n",
       "10000      Columbus Avenue  [Doorman, Elevator, Fitness Center, Cats Allow...   \n",
       "\n",
       "       latitude  listing_id  longitude                        manager_id  \\\n",
       "10      40.7145     7211212   -73.9425  5ba989232d0489da1b5f2c45f6688adc   \n",
       "10000   40.7947     7150865   -73.9667  7533621a882f71e25173b27e3139d83d   \n",
       "\n",
       "                                                  photos  price  \\\n",
       "10     [https://photos.renthop.com/2/7211212_1ed4542e...   3000   \n",
       "10000  [https://photos.renthop.com/2/7150865_be3306c5...   5465   \n",
       "\n",
       "                street_address interest_level  \n",
       "10     792 Metropolitan Avenue         medium  \n",
       "10000      808 Columbus Avenue            low  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bathrooms', 'bedrooms', 'building_id', 'created', 'description',\n",
       "       'display_address', 'features', 'latitude', 'listing_id', 'longitude',\n",
       "       'manager_id', 'photos', 'price', 'street_address', 'interest_level',\n",
       "       'day', 'month', 'year', 'building_id_0', 'building_id_1',\n",
       "       'building_id_2', 'manager_id_0', 'manager_id_1', 'manager_id_2',\n",
       "       'len_features', 'cleaned_description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. With description as BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bow= sparse.hstack((train[['bathrooms', 'bedrooms', 'latitude', 'longitude','price','day', 'month', 'year','building_id_0', 'building_id_1',\n",
    "       'building_id_2', 'manager_id_0', 'manager_id_1', 'manager_id_2' ,'len_features']],count_vect_features_train,\\\n",
    "               count_vect_display_address_train, count_vect_strt_address_train, count_vect_description_train\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34546, 11321)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bow = sparse.hstack((test[['bathrooms', 'bedrooms', 'latitude', 'longitude','price','day', 'month', 'year','building_id_0', 'building_id_1',\n",
    "       'building_id_2', 'manager_id_0', 'manager_id_1', 'manager_id_2' ,'len_features']],count_vect_features_test,\\\n",
    "               count_vect_display_address_test, count_vect_strt_address_test, count_vect_description_test\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14806, 11321)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  With description as TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf= sparse.hstack((train[['bathrooms', 'bedrooms', 'latitude', 'longitude','price','day', 'month', 'year','building_id_0', 'building_id_1',\n",
    "       'building_id_2', 'manager_id_0', 'manager_id_1', 'manager_id_2' ,'len_features']],count_vect_features_train,\\\n",
    "               count_vect_display_address_train, count_vect_strt_address_train, tfidf_description_train\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34546, 11321)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf = sparse.hstack((test[['bathrooms', 'bedrooms', 'latitude', 'longitude','price','day', 'month', 'year','building_id_0', 'building_id_1',\n",
    "       'building_id_2', 'manager_id_0', 'manager_id_1', 'manager_id_2' ,'len_features']],count_vect_features_test,\\\n",
    "               count_vect_display_address_test, count_vect_strt_address_test, tfidf_description_test\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14806, 11321)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  With description as AvgW2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_avgw2v= sparse.hstack((train[['bathrooms', 'bedrooms', 'latitude', 'longitude','price','day', 'month', 'year','building_id_0', 'building_id_1',\n",
    "       'building_id_2', 'manager_id_0', 'manager_id_1', 'manager_id_2' ,'len_features']],count_vect_features_train,\\\n",
    "               count_vect_display_address_train, count_vect_strt_address_train, sent_to_vec_avgw2v_train\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34546, 2610)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_avgw2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_avgw2v= sparse.hstack((test[['bathrooms', 'bedrooms', 'latitude', 'longitude','price','day', 'month', 'year','building_id_0', 'building_id_1',\n",
    "       'building_id_2', 'manager_id_0', 'manager_id_1', 'manager_id_2' ,'len_features']],count_vect_features_test,\\\n",
    "               count_vect_display_address_test, count_vect_strt_address_test, sent_to_vec_avgw2v_test\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14806, 2610)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_avgw2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.   With description as W2V using TFIDFW2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidfw2v = sparse.hstack((train[['bathrooms', 'bedrooms', 'latitude', 'longitude','price','day', 'month', 'year','building_id_0', 'building_id_1',\n",
    "       'building_id_2', 'manager_id_0', 'manager_id_1', 'manager_id_2' ,'len_features']],count_vect_features_train,\\\n",
    "               count_vect_display_address_train, count_vect_strt_address_train, sent_to_vec_tfidfw2v\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34546, 2610)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidfw2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidfw2v= sparse.hstack((test[['bathrooms', 'bedrooms', 'latitude', 'longitude','price','day', 'month', 'year','building_id_0', 'building_id_1',\n",
    "       'building_id_2', 'manager_id_0', 'manager_id_1', 'manager_id_2' ,'len_features']],count_vect_features_test,\\\n",
    "               count_vect_display_address_test, count_vect_strt_address_test, sent_to_vec_tfidfw2v_test\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14806, 2610)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidfw2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pickling the datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pickling the train data\n",
    "import pickle\n",
    "\n",
    "with open('./pickle/train_bow.pkl', 'wb') as f:\n",
    "    pickle.dump(train_bow,f)\n",
    "\n",
    "with open('./pickle/train_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(train_tfidf,f)\n",
    "    \n",
    "with open('./pickle/train_avgw2v.pkl', 'wb') as f:\n",
    "    pickle.dump(train_avgw2v,f)\n",
    "    \n",
    "with open('./pickle/train_tfidfw2v.pkl', 'wb') as f:\n",
    "    pickle.dump(train_tfidfw2v,f)\n",
    "    \n",
    "with open('./pickle/y_train.pkl', 'wb') as f:\n",
    "    pickle.dump(train['interest_level'],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pickling the test data\n",
    "\n",
    "with open('./pickle/test_bow.pkl', 'wb') as f:\n",
    "    pickle.dump(test_bow,f)\n",
    "\n",
    "with open('./pickle/test_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(test_tfidf,f)\n",
    "    \n",
    "with open('./pickle/test_avgw2v.pkl', 'wb') as f:\n",
    "    pickle.dump(test_avgw2v,f)\n",
    "    \n",
    "with open('./pickle/test_tfidfw2v.pkl', 'wb') as f:\n",
    "    pickle.dump(test_tfidfw2v,f)\n",
    "    \n",
    "with open('./pickle/y_test.pkl', 'wb') as f:\n",
    "    pickle.dump(test['interest_level'],f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel, 2019 update 2)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_2019u2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
